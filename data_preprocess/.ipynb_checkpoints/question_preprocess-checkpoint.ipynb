{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Alphabet(dict):\n",
    "    def __init__(self, start_id=1):\n",
    "        self.fid = start_id\n",
    "    \n",
    "    def add(self, item):\n",
    "        idx = self.get(item, None)\n",
    "        if idx is None:\n",
    "            idx = self.fid\n",
    "            self[item] = idx\n",
    "            self.fid += 1\n",
    "        return idx\n",
    "    \n",
    "    def dump(self, fname):\n",
    "        with open(fname, 'w') as out:\n",
    "            for k in sorted(self.keys()):\n",
    "                out.write(\"{}\\t{}\\n\".format(k, self[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_embed(fname):\n",
    "    f = open(fname)\n",
    "    cnt, vocab_size, embed_dim = 0, 0, 0\n",
    "    embed_dict = {}\n",
    "    print 'Load embedding file start!'\n",
    "    for line in f:\n",
    "        cnt += 1\n",
    "        if cnt % 10000 == 0:\n",
    "            print cnt\n",
    "        terms = line.strip().split(' ')\n",
    "        if len(terms) == 2:\n",
    "            vocab_size = int(terms[0])\n",
    "            embed_dim = int(terms[1])\n",
    "        if len(terms) == embed_dim + 1:\n",
    "            embed_dict[terms[0]] = np.array([float(ii) for ii in terms[1:]])\n",
    "    print 'Load embedding file finish!'\n",
    "    return embed_dict, vocab_size, embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_embed(embed_file):\n",
    "    alphabet, embed_mat = Alphabet(), []\n",
    "    embed_dict, vocab_size, embed_dim = load_embed(embed_file)\n",
    "    unknown_word_idx = 0\n",
    "    embed_mat.append(np.random.uniform(-0.25, 0.25, embed_dim))\n",
    "    for word in embed_dict:\n",
    "        alphabet.add(word)\n",
    "        embed_mat.append(embed_dict[word])\n",
    "    dummy_word_idx = alphabet.fid\n",
    "    embed_mat.append(np.zeros(embed_dim))\n",
    "    return alphabet, embed_mat, unknown_word_idx, dummy_word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_embed_file = '../ieee_zhihu_cup/char_embedding.txt'\n",
    "#word_embed_file = '../ieee_zhihu_cup/word_embedding.txt'\n",
    "char_alphabet, char_embed_mat, unknown_char_idx, dummy_char_idx = parse_embed(char_embed_file)\n",
    "#word_alphabet, word_embed_mat, unknown_word_idx, dummy_word_idx = parse_embed(word_embed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_question(fname, split=False, rate=None):\n",
    "    f = open(fname)\n",
    "    cnt, idx, title_char, title_word, desc_char, desc_word = 0, [], [], [], [], []\n",
    "    print 'Load question file start!'\n",
    "    for line in f:\n",
    "        cnt += 1\n",
    "        if cnt % 10000 == 0:\n",
    "            print cnt\n",
    "        terms = line.strip().split('\\t')\n",
    "        idx.append(terms[0])\n",
    "        if len(terms) == 5:\n",
    "            title_char.append(terms[1])\n",
    "            title_word.append(terms[2])\n",
    "            desc_char.append(terms[3])\n",
    "            desc_word.append(terms[4])\n",
    "        elif len(terms) == 4:\n",
    "            title_char.append(terms[1])\n",
    "            title_word.append(terms[2])\n",
    "            desc_char.append(terms[3])\n",
    "            desc_word.append('')\n",
    "        elif len(terms) == 3:\n",
    "            title_char.append(terms[1])\n",
    "            title_word.append(terms[2])\n",
    "            desc_char.append('')\n",
    "            desc_word.append('')\n",
    "        elif len(terms) == 1:\n",
    "            title_char.append('')\n",
    "            title_word.append('')\n",
    "            desc_char.append('')\n",
    "            desc_word.append('')\n",
    "    print 'Load question file finish!'\n",
    "    if split:\n",
    "        ids = np.arange(cnt)\n",
    "        np.random.seed(1024)\n",
    "        np.random.shuffle(ids)\n",
    "        train_id = ids[:int(cnt*rate)]\n",
    "        val_id = ids[int(cnt*rate):]\n",
    "        print \"Finished\"\n",
    "        return [idx[i] for i in train_id], [title_char[i] for i in train_id], \\\n",
    "                [title_word[i] for i in train_id], [desc_char[i] for i in train_id], \\\n",
    "                [desc_word[i] for i in train_id], \\\n",
    "                [idx[i] for i in val_id], [title_char[i] for i in val_id], \\\n",
    "                [title_word[i] for i in val_id], [desc_char[i] for i in val_id], \\\n",
    "                [desc_word[i] for i in val_id]\n",
    "    print \"Finished\"\n",
    "    return idx, title_char, title_word, desc_char, desc_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert2indices(data, alphabet, unknown_word_idx, dummy_word_idx, max_length):\n",
    "    data_idx = []\n",
    "    for item in data:\n",
    "        item_arr = [ii for ii in item.split(',') if ii != '']\n",
    "        ex = np.ones(max_length) * dummy_word_idx\n",
    "        for i, word in enumerate(item_arr):\n",
    "            if i >= max_length:\n",
    "                break\n",
    "            idx = alphabet.get(word, unknown_word_idx)\n",
    "            ex[i] = idx\n",
    "        data_idx.append(ex)\n",
    "    data_idx = np.array(data_idx).astype('int32')\n",
    "    return data_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_train_file = '../ieee_zhihu_cup/question_train_set.txt'\n",
    "question_test_file = '../ieee_zhihu_cup/question_eval_set.txt'\n",
    "train_idx, train_title_char, train_title_word, train_desc_char, train_desc_word, \\\n",
    "val_idx, val_title_char, val_title_word, val_desc_char, val_desc_word \\\n",
    "            = load_question(question_train_file, split=True, rate=0.9)\n",
    "train_idx_all, train_title_char_all, train_title_word_all, train_desc_char_all, \\\n",
    "                train_desc_word_all = load_question(question_train_file)\n",
    "test_idx, test_title_char, test_title_word, test_desc_char, test_desc_word \\\n",
    "                           = load_question(question_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_char_max_length = 85#22\n",
    "#title_word_max_length = 50#30#13\n",
    "desc_char_max_length = 300#117\n",
    "#desc_word_max_length = 150#120#58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_title_char_indices = convert2indices(train_title_char, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           title_char_max_length)\n",
    "#train_title_word_indices = convert2indices(train_title_word, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           title_word_max_length)\n",
    "train_desc_char_indices = convert2indices(train_desc_char, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           desc_char_max_length)\n",
    "#train_desc_word_indices = convert2indices(train_desc_word, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           desc_word_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_title_char_indices = convert2indices(val_title_char, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           title_char_max_length)\n",
    "#val_title_word_indices = convert2indices(val_title_word, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           title_word_max_length)\n",
    "val_desc_char_indices = convert2indices(val_desc_char, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           desc_char_max_length)\n",
    "#val_desc_word_indices = convert2indices(val_desc_word, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           desc_word_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './embed'\n",
    "np.save('{}/char_embed_mat.npy'.format(basedir), char_embed_mat)\n",
    "del char_embed_mat\n",
    "#np.save('{}/word_embed_mat.npy'.format(basedir), word_embed_mat)\n",
    "#del word_embed_mat\n",
    "print 'Save embedding finished!'\n",
    "basedir = './train'\n",
    "#np.save('{}/train_idx.npy'.format(basedir), train_idx)\n",
    "#del train_idx\n",
    "np.save('{}/train_title_char_indices_2.npy'.format(basedir), train_title_char_indices)\n",
    "del train_title_char_indices\n",
    "#np.save('{}/train_title_word_indices_2.npy'.format(basedir), train_title_word_indices)\n",
    "#del train_title_word_indices\n",
    "np.save('{}/train_desc_char_indices_2.npy'.format(basedir), train_desc_char_indices)\n",
    "del train_desc_char_indices\n",
    "#np.save('{}/train_desc_word_indices_2.npy'.format(basedir), train_desc_word_indices)\n",
    "#del train_desc_word_indices\n",
    "print 'Save train data finished!'\n",
    "basedir = './val'\n",
    "#np.save('{}/val_idx.npy'.format(basedir), val_idx)\n",
    "#del val_idx\n",
    "np.save('{}/val_title_char_indices_2.npy'.format(basedir), val_title_char_indices)\n",
    "del val_title_char_indices\n",
    "#np.save('{}/val_title_word_indices_2.npy'.format(basedir), val_title_word_indices)\n",
    "#del val_title_word_indices\n",
    "np.save('{}/val_desc_char_indices_2.npy'.format(basedir), val_desc_char_indices)\n",
    "del val_desc_char_indices\n",
    "#np.save('{}/val_desc_word_indices_2.npy'.format(basedir), val_desc_word_indices)\n",
    "#del val_desc_word_indices\n",
    "print 'Save val data finished!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_title_char_indices_all = convert2indices(train_title_char_all, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           title_char_max_length)\n",
    "#train_title_word_indices_all = convert2indices(train_title_word_all, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           title_word_max_length)\n",
    "train_desc_char_indices_all = convert2indices(train_desc_char_all, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           desc_char_max_length)\n",
    "#train_desc_word_indices_all = convert2indices(train_desc_word_all, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           desc_word_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_title_char_indices = convert2indices(test_title_char, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           title_char_max_length)\n",
    "#test_title_word_indices = convert2indices(test_title_word, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           title_word_max_length)\n",
    "test_desc_char_indices = convert2indices(test_desc_char, char_alphabet, \\\n",
    "                                           unknown_char_idx, dummy_char_idx, \\\n",
    "                                           desc_char_max_length)\n",
    "#test_desc_word_indices = convert2indices(test_desc_word, word_alphabet, \\\n",
    "#                                           unknown_word_idx, dummy_word_idx, \\\n",
    "#                                           desc_word_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = './train_all'\n",
    "#np.save('{}/train_idx_all.npy'.format(basedir), train_idx_all)\n",
    "np.save('{}/train_title_char_indices_all_2.npy'.format(basedir), train_title_char_indices_all)\n",
    "#np.save('{}/train_title_word_indices_all_2.npy'.format(basedir), train_title_word_indices_all)\n",
    "np.save('{}/train_desc_char_indices_all_2.npy'.format(basedir), train_desc_char_indices_all)\n",
    "#np.save('{}/train_desc_word_indices_all_2.npy'.format(basedir), train_desc_word_indices_all)\n",
    "print 'Save train all data finished!'\n",
    "basedir = './test'\n",
    "#np.save('{}/test_idx.npy'.format(basedir), test_idx)\n",
    "np.save('{}/test_title_char_indices_2.npy'.format(basedir), test_title_char_indices)\n",
    "#np.save('{}/test_title_word_indices_2.npy'.format(basedir), test_title_word_indices)\n",
    "np.save('{}/test_desc_char_indices_2.npy'.format(basedir), test_desc_char_indices)\n",
    "#np.save('{}/test_desc_word_indices_2.npy'.format(basedir), test_desc_word_indices)\n",
    "print 'Save test data finished!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
